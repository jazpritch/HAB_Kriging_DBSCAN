{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kriging of Water Temperature Data\n",
    "# This code performs spatial interpolation using Ordinary Kriging to create seasonal water temperature maps.  \n",
    "# Refer to the full report for details on data preprocessing, variogram selection, and results: [https://drive.google.com/file/d/1yXK9QeRNYC_XvNnIGkGfljURp_otVy3G/view?usp=sharing].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Step 1: Load spatial boundary data for Lake Erie\n",
    "# The Lake Erie boundary is used to ensure interpolation stays within the lake area\n",
    "lake_boundary = gpd.read_file(\"lake-erie_812.geojson\")\n",
    "\n",
    "# Step 2: Load and clean water temperature data\n",
    "# The cleaned data includes water temperature measurements with spatial coordinates\n",
    "water_temp = pd.read_csv(\"cleaned_water_temp.csv\")\n",
    "water_temp['geometry'] = water_temp.apply(lambda row: Point(row['Longitude'], row['Latitude']), axis=1)\n",
    "gdf_temp = gpd.GeoDataFrame(water_temp, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "# Add pseudo-points along the boundary to improve kriging near the edges\n",
    "# These points help prevent edge effects during interpolation by providing artificial data constraints\n",
    "pseudo_points = lake_boundary.sample(20).copy()\n",
    "pseudo_points['Temperature'] = gdf_temp['Temperature'].mean()  # Use mean temperature as a reasonable approximation\n",
    "pseudo_gdf = gpd.GeoDataFrame(pseudo_points, geometry=pseudo_points.geometry, crs='EPSG:4326')\n",
    "combined_gdf = pd.concat([gdf_temp, pseudo_gdf])\n",
    "\n",
    "# Step 3: Define the grid for kriging\n",
    "# Create a fine grid for interpolation within the lake boundary\n",
    "xmin, ymin, xmax, ymax = lake_boundary.total_bounds\n",
    "x = np.linspace(xmin, xmax, 200)\n",
    "y = np.linspace(ymin, ymax, 200)\n",
    "gridx, gridy = np.meshgrid(x, y)\n",
    "\n",
    "# Step 4: Apply Ordinary Kriging\n",
    "# Kriging is used for geostatistical interpolation; the linear variogram model was selected for simplicity\n",
    "krige = OrdinaryKriging(\n",
    "    combined_gdf['Longitude'], combined_gdf['Latitude'], combined_gdf['Temperature'],\n",
    "    variogram_model=\"linear\", verbose=False, enable_plotting=False\n",
    ")\n",
    "z, ss = krige.execute(\"grid\", gridx, gridy)\n",
    "\n",
    "# Step 5: Mask kriging output to lake boundary\n",
    "# Only include interpolated points within the Lake Erie boundary\n",
    "grid_points = [Point(x, y) for x, y in zip(gridx.flatten(), gridy.flatten())]\n",
    "grid_gdf = gpd.GeoDataFrame({'Temperature': z.flatten()}, geometry=grid_points, crs='EPSG:4326')\n",
    "masked_grid = gpd.sjoin(grid_gdf, lake_boundary, how='inner', predicate='intersects')\n",
    "\n",
    "# Step 6: Save and visualize the output\n",
    "# Generate seasonal kriging maps for water temperature\n",
    "years = range(2009, 2023 + 1)  # Adjust this range as needed\n",
    "seasons = {'Winter': [12, 1, 2], 'Spring': [3, 4, 5], 'Summer': [6, 7, 8], 'Fall': [9, 10, 11]}\n",
    "\n",
    "for year in years:\n",
    "    for season, months in seasons.items():\n",
    "        seasonal_data = combined_gdf[\n",
    "            (combined_gdf['Year'] == year) & (combined_gdf['Month'].isin(months))\n",
    "        ]\n",
    "        if not seasonal_data.empty:\n",
    "            # Perform kriging for the seasonal data\n",
    "            seasonal_krige = OrdinaryKriging(\n",
    "                seasonal_data['Longitude'], seasonal_data['Latitude'], seasonal_data['Temperature'],\n",
    "                variogram_model=\"linear\", verbose=False, enable_plotting=False\n",
    "            )\n",
    "            z_season, ss_season = seasonal_krige.execute(\"grid\", gridx, gridy)\n",
    "            \n",
    "            # Create a seasonal map\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.contourf(gridx, gridy, z_season, levels=20, cmap=\"coolwarm\")\n",
    "            lake_boundary.boundary.plot(color='black', linewidth=0.5, ax=plt.gca())\n",
    "            plt.title(f\"{season} Water Temperature Map for {year}\")\n",
    "            plt.colorbar(label=\"Temperature (Â°C)\")\n",
    "            plt.savefig(f\"{season}_{year}_Water_Temperature.png\")\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Analysis of Water Quality and Algal Data\n",
    "# This code applies Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to identify spatial clusters and hotspots of water quality parameters (temperature, dissolved oxygen) and algal concentrations (CI_cyano).\n",
    "# Refer to the full report for details on data preprocessing, parameter optimization, and clustering results: [https://drive.google.com/file/d/1yXK9QeRNYC_XvNnIGkGfljURp_otVy3G/view?usp=sharing]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize maps into a panel\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from rasterstats import zonal_stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def extract_algal_data(tif_path, shapefile):\n",
    "    \"\"\"Extract algal data from TIFF and join with shapefile.\"\"\"\n",
    "    stats = zonal_stats(shapefile, tif_path, stats=[\"mean\"], geojson_out=True)\n",
    "    algal_data = gpd.GeoDataFrame.from_features(stats)\n",
    "    algal_data = algal_data.rename(columns={\"mean\": \"Algal\"})\n",
    "    return algal_data\n",
    "\n",
    "def perform_hotspot_analysis(data, clusters=5):\n",
    "    \"\"\"Perform clustering analysis on dissolved oxygen, temperature, and algal data.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    data[['DO', 'Temp', 'Algal']] = scaler.fit_transform(data[['DO', 'Temp', 'Algal']])\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=clusters, random_state=42)\n",
    "    data['cluster'] = kmeans.fit_predict(data[['DO', 'Temp', 'Algal']])\n",
    "    return data\n",
    "\n",
    "def rasterize_clusters(data, lake_boundary, resolution=100):\n",
    "    \"\"\"Rasterize cluster data.\"\"\"\n",
    "    xmin, ymin, xmax, ymax = lake_boundary.total_bounds\n",
    "    x = np.linspace(xmin, xmax, resolution)\n",
    "    y = np.linspace(ymin, ymax, resolution)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    grid = np.full((resolution, resolution), -1, dtype=int)\n",
    "    \n",
    "    for idx, row in data.iterrows():\n",
    "        ix = np.argmin(np.abs(x - row.geometry.x))\n",
    "        iy = np.argmin(np.abs(y - row.geometry.y))\n",
    "        grid[iy, ix] = row['cluster']\n",
    "    \n",
    "    return grid, (xmin, xmax, ymin, ymax)\n",
    "\n",
    "# Map seasons to algal quarters\n",
    "season_to_quarter = {\"DJF\": \"Q1\", \"MAM\": \"Q2\", \"JJA\": \"Q3\", \"SON\": \"Q4\"}\n",
    "\n",
    "# Load Lake Erie boundary\n",
    "lake_boundary = gpd.read_file(f\"../Nutrient_Data/lake-erie_812.geojson\")\n",
    "\n",
    "# Define years and seasons\n",
    "years = [2011, 2017, 2019, 2022]\n",
    "seasons = {\"DJF\": [12, 1, 2], \"MAM\": [3, 4, 5], \"JJA\": [6, 7, 8], \"SON\": [9, 10, 11]}\n",
    "\n",
    "# Adjust global font sizes\n",
    "plt.rcParams.update({'font.size': 12})  # Default font size for plots\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(len(years), len(seasons), figsize=(20, 5 * len(years)))\n",
    "fig.suptitle(\"Rasterized Clusters Comparison Across Years and Seasons\", fontsize=24)\n",
    "\n",
    "# Create a list to store the image objects\n",
    "images = []\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    for j, (season, months) in enumerate(seasons.items()):\n",
    "        print(f\"Processing {season}, {year}...\")\n",
    "        \n",
    "        # File paths\n",
    "        temp_file = f\"../Nutrient_Data/shapefile_outputs/lake_erie_{year}_{season}_interpolated.shp\"\n",
    "        do_file = f\"../Nutrient_Data/shapefile_outputs_DO/lake_erie_{year}_{season}_DO_interpolated.shp\"\n",
    "        algal_tif = f\"../Algal_Data/algal_seasonal_spatial/seasonal_avg_{year}-{season_to_quarter[season]}.tif\"\n",
    "        \n",
    "        try:\n",
    "            # Load temperature and dissolved oxygen shapefiles\n",
    "            temp_data = gpd.read_file(temp_file)\n",
    "            do_data = gpd.read_file(do_file)\n",
    "            \n",
    "            # Rename columns for consistency\n",
    "            temp_data = temp_data.rename(columns={\"temp\": \"Temp\"})\n",
    "            do_data = do_data.rename(columns={\"DO\": \"DO\"})\n",
    "            \n",
    "            # Merge temperature and dissolved oxygen data\n",
    "            merged_data = gpd.sjoin(temp_data, do_data, how=\"inner\", predicate=\"intersects\")\n",
    "            \n",
    "            # Extract algal data\n",
    "            algal_data = extract_algal_data(algal_tif, merged_data)\n",
    "            merged_data[\"Algal\"] = algal_data[\"Algal\"]\n",
    "            \n",
    "            # Perform clustering\n",
    "            clustered_data = perform_hotspot_analysis(merged_data, clusters=6)  # Adjusted clusters\n",
    "            \n",
    "            # Rasterize clusters\n",
    "            grid, extent = rasterize_clusters(clustered_data, lake_boundary)\n",
    "            \n",
    "            # Plot rasterized data\n",
    "            ax = axes[i, j]\n",
    "            smoothed_grid = gaussian_filter(grid, sigma=1)\n",
    "            im = ax.imshow(smoothed_grid, extent=extent, origin='lower', cmap='coolwarm', alpha=0.8)\n",
    "            images.append(im)\n",
    "            lake_boundary.plot(ax=ax, edgecolor=\"black\", facecolor=\"none\", linewidth=1.5)\n",
    "            ax.set_title(f\"{season} {year}\", fontsize=16)  # Larger title font\n",
    "            ax.axis(\"off\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Missing data for {season}, {year}. Skipping...\")\n",
    "            axes[i, j].text(0.5, 0.5, f\"No data\\n{season} {year}\", ha='center', va='center', fontsize=14, color=\"red\")\n",
    "            axes[i, j].axis(\"off\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}, {year}: {e}\")\n",
    "            axes[i, j].text(0.5, 0.5, f\"Error\\n{season} {year}\", ha='center', va='center', fontsize=14, color=\"red\")\n",
    "            axes[i, j].axis(\"off\")\n",
    "\n",
    "# Adjust the layout to make room for the colorbar\n",
    "plt.tight_layout(rect=[0, 0.03, 0.9, 0.95])\n",
    "\n",
    "# Add a colorbar to the right of the subplots\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(images[0], cax=cbar_ax)\n",
    "cbar.set_label('Cluster', fontsize=16)\n",
    "cbar.ax.tick_params(labelsize=14)  # Increase tick label size\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
